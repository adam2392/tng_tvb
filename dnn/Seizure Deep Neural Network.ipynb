{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "from functools import reduce\n",
    "import math as m\n",
    "\n",
    "import scipy.io\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "from sklearn.preprocessing import scale\n",
    "# from utils import augment_EEG\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Coordinate Functions\n",
    "\n",
    "The following functions will be used for modifying the data coordinates, specifically the xyz coordinates of the electrodes handed in assuming mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2sph(x, y, z):\n",
    "    \"\"\"\n",
    "    Transform Cartesian coordinates to spherical\n",
    "    :param x: X coordinate\n",
    "    :param y: Y coordinate\n",
    "    :param z: Z coordinate\n",
    "    :return: radius, elevation, azimuth\n",
    "    \"\"\"\n",
    "    x2_y2 = x**2 + y**2\n",
    "    r = m.sqrt(x2_y2 + z**2)                    # r\n",
    "    elev = m.atan2(z, m.sqrt(x2_y2))            # Elevation\n",
    "    az = m.atan2(y, x)                          # Azimuth\n",
    "    return r, elev, az\n",
    "\n",
    "\n",
    "def pol2cart(theta, rho):\n",
    "    \"\"\"\n",
    "    Transform polar coordinates to Cartesian\n",
    "    :param theta: angle value\n",
    "    :param rho: radius value\n",
    "    :return: X, Y\n",
    "    \"\"\"\n",
    "    return rho * m.cos(theta), rho * m.sin(theta)\n",
    "\n",
    "def azim_proj(pos):\n",
    "    \"\"\"\n",
    "    Computes the Azimuthal Equidistant Projection of input point in 3D Cartesian Coordinates.\n",
    "    Imagine a plane being placed against (tangent to) a globe. If\n",
    "    a light source inside the globe projects the graticule onto\n",
    "    the plane the result would be a planar, or azimuthal, map\n",
    "    projection.\n",
    "\n",
    "    - param pos: position in 3D Cartesian coordinates\n",
    "    \n",
    "    - return: projected coordinates using Azimuthal Equidistant Projection\n",
    "    \"\"\"\n",
    "    [r, elev, az] = cart2sph(pos[0], pos[1], pos[2])\n",
    "    return pol2cart(az, m.pi / 2 - elev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-26.63</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-46.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-30.11</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-46.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-33.59</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-46.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-37.07</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-45.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-40.55</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-45.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x     y      z\n",
       "0 -26.63  0.70 -46.78\n",
       "1 -30.11  0.87 -46.46\n",
       "2 -33.59  1.05 -46.15\n",
       "3 -37.07  1.22 -45.84\n",
       "4 -40.55  1.40 -45.53"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.623028</td>\n",
       "      <td>0.068949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.565304</td>\n",
       "      <td>0.074122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.510964</td>\n",
       "      <td>0.078491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.459983</td>\n",
       "      <td>0.080960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.412250</td>\n",
       "      <td>0.083284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0 -2.623028  0.068949\n",
       "1 -2.565304  0.074122\n",
       "2 -2.510964  0.078491\n",
       "3 -2.459983  0.080960\n",
       "4 -2.412250  0.083284"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in xyz data\n",
    "rootdir = os.getcwd()\n",
    "locs = pd.read_csv(os.path.join(rootdir, 'seeg.txt'), delim_whitespace=True, \\\n",
    "                   header=None, names=['chan', 'x', 'y', 'z'], \\\n",
    "                      dtype={'chan': str, 'x': np.float64,\\\n",
    "                             'y': np.float64, 'z': np.float64} )\n",
    "\n",
    "chan_names = locs['chan']\n",
    "locs_3d = locs[['x','y','z']]\n",
    "# convert 3d coords to 2d\n",
    "locs_2d = []\n",
    "for idx, coord in locs_3d.iterrows():\n",
    "    locs_2d.append(azim_proj(coord))\n",
    "locs_2d = pd.DataFrame(locs_2d)\n",
    "\n",
    "display(locs_3d.head())\n",
    "display(locs_2d.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Neural Networks (CNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_images(locs, features, n_gridpoints, normalize=True,\n",
    "               augment=False, pca=False, std_mult=0.1, n_components=2, edgeless=False):\n",
    "    \"\"\"\n",
    "    Generates EEG images given electrode locations in 2D space and multiple feature values for each electrode\n",
    "\n",
    "    - param locs: An array with shape [n_electrodes, 2] containing X, Y\n",
    "                        coordinates for each electrode.\n",
    "    - param features: Feature matrix as [n_samples, n_features]\n",
    "                                Features are as columns.\n",
    "                                Features corresponding to each frequency band are concatenated.\n",
    "                                (alpha1, alpha2, ..., beta1, beta2,...)\n",
    "    - param n_gridpoints: Number of pixels in the output images\n",
    "    - param normalize:   Flag for whether to normalize each band over all samples\n",
    "    - param augment:     Flag for generating augmented images\n",
    "    - param pca:         Flag for PCA based data augmentation\n",
    "    - param std_mult     Multiplier for std of added noise\n",
    "    - param n_components: Number of components in PCA to retain for augmentation\n",
    "    - param edgeless:    If True generates edgeless images by adding artificial channels\n",
    "                        at four corners of the image with value = 0 (default=False).\n",
    "    :return:            Tensor of size [samples, colors, W, H] containing generated\n",
    "                        images.\n",
    "    \"\"\"\n",
    "    feat_array_temp = []\n",
    "    nElectrodes = locs.shape[0]     # Number of electrodes\n",
    "    \n",
    "    # Test whether the feature vector length is divisible by number of electrodes\n",
    "    assert features.shape[1] % nElectrodes == 0\n",
    "    \n",
    "    # feature vector len / number of electrodes\n",
    "    n_colors = features.shape[1] / nElectrodes\n",
    "    for c in range(n_colors):\n",
    "        feat_array_temp.append(features[:, c * nElectrodes : nElectrodes * (c+1)])\n",
    "    if augment:\n",
    "        if pca:\n",
    "            for c in range(n_colors):\n",
    "                feat_array_temp[c] = augment_EEG(feat_array_temp[c], std_mult, pca=True, n_components=n_components)\n",
    "        else:\n",
    "            for c in range(n_colors):\n",
    "                feat_array_temp[c] = augment_EEG(feat_array_temp[c], std_mult, pca=False, n_components=n_components)\n",
    "    nSamples = features.shape[0]\n",
    "    # Interpolate the values\n",
    "    grid_x, grid_y = np.mgrid[\n",
    "                     min(locs[:, 0]):max(locs[:, 0]):n_gridpoints*1j,\n",
    "                     min(locs[:, 1]):max(locs[:, 1]):n_gridpoints*1j\n",
    "                     ]\n",
    "    temp_interp = []\n",
    "    for c in range(n_colors):\n",
    "        temp_interp.append(np.zeros([nSamples, n_gridpoints, n_gridpoints]))\n",
    "    # Generate edgeless images\n",
    "    if edgeless:\n",
    "        min_x, min_y = np.min(locs, axis=0)\n",
    "        max_x, max_y = np.max(locs, axis=0)\n",
    "        locs = np.append(locs, np.array([[min_x, min_y], [min_x, max_y],[max_x, min_y],[max_x, max_y]]),axis=0)\n",
    "        for c in range(n_colors):\n",
    "            feat_array_temp[c] = np.append(feat_array_temp[c], np.zeros((nSamples, 4)), axis=1)\n",
    "    # Interpolating\n",
    "    for i in xrange(nSamples):\n",
    "        for c in range(n_colors):\n",
    "            temp_interp[c][i, :, :] = griddata(locs, feat_array_temp[c][i, :], (grid_x, grid_y),\n",
    "                                    method='cubic', fill_value=np.nan)\n",
    "        print('Interpolating {0}/{1}\\r'.format(i+1, nSamples), end='\\r')\n",
    "    # Normalizing\n",
    "    for c in range(n_colors):\n",
    "        if normalize:\n",
    "            temp_interp[c][~np.isnan(temp_interp[c])] = \\\n",
    "                scale(temp_interp[c][~np.isnan(temp_interp[c])])\n",
    "        temp_interp[c] = np.nan_to_num(temp_interp[c])\n",
    "    return np.swapaxes(np.asarray(temp_interp), 0, 1)     # swap axes to have [samples, colors, W, H]\n",
    "\n",
    "def build_cnn(input_var=None, w_init=None, n_layers=(4, 2, 1), n_filters_first=32, imsize=32, n_colors=3):\n",
    "    \"\"\"\n",
    "    Builds a VGG style CNN network followed by a fully-connected layer and a softmax layer.\n",
    "    Stacks are separated by a maxpool layer. Number of kernels in each layer is twice\n",
    "    the number in previous stack.\n",
    "    input_var: Theano variable for input to the network\n",
    "    outputs: pointer to the output of the last layer of network (softmax)\n",
    "\n",
    "    :param input_var: theano variable as input to the network\n",
    "    :param w_init: Initial weight values\n",
    "    :param n_layers: number of layers in each stack. An array of integers with each\n",
    "                    value corresponding to the number of layers in each stack.\n",
    "                    (e.g. [4, 2, 1] == 3 stacks with 4, 2, and 1 layers in each.\n",
    "    :param n_filters_first: number of filters in the first layer\n",
    "    :param imSize: Size of the image\n",
    "    :param n_colors: Number of color channels (depth)\n",
    "    :return: a pointer to the output of last layer\n",
    "    \"\"\"\n",
    "    weights = []        # Keeps the weights for all layers\n",
    "    count = 0\n",
    "    # If no initial weight is given, initialize with GlorotUniform\n",
    "    if w_init is None:\n",
    "        w_init = [lasagne.init.GlorotUniform()] * sum(n_layers)\n",
    "    # Input layer\n",
    "    network = InputLayer(shape=(None, n_colors, imsize, imsize),\n",
    "                                        input_var=input_var)\n",
    "    for i, s in enumerate(n_layers):\n",
    "        for l in range(s):\n",
    "            network = Conv2DLayer(network, num_filters=n_filters_first * (2 ** i), filter_size=(3, 3),\n",
    "                          W=w_init[count], pad='same')\n",
    "            count += 1\n",
    "            weights.append(network.W)\n",
    "        network = MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "    return network, weights\n",
    "\n",
    "\n",
    "def build_convpool_max(input_vars, nb_classes, imsize=32, n_colors=3, n_timewin=3):\n",
    "    \"\"\"\n",
    "    Builds the complete network with maxpooling layer in time.\n",
    "\n",
    "    :param input_vars: list of EEG images (one image per time window)\n",
    "    :param nb_classes: number of classes\n",
    "    :param imsize: size of the input image (assumes a square input)\n",
    "    :param n_colors: number of color channels in the image\n",
    "    :param n_timewin: number of time windows in the snippet\n",
    "    :return: a pointer to the output of last layer\n",
    "    \"\"\"\n",
    "    convnets = []\n",
    "    w_init = None\n",
    "    # Build 7 parallel CNNs with shared weights\n",
    "    for i in range(n_timewin):\n",
    "        if i == 0:\n",
    "            convnet, w_init = build_cnn(input_vars[i], imsize=imsize, n_colors=n_colors)\n",
    "        else:\n",
    "            convnet, _ = build_cnn(input_vars[i], w_init=w_init, imsize=imsize, n_colors=n_colors)\n",
    "        convnets.append(convnet)\n",
    "    # convpooling using Max pooling over frames\n",
    "    convpool = ElemwiseMergeLayer(convnets, theano.tensor.maximum)\n",
    "    # A fully-connected layer of 512 units with 50% dropout on its inputs:\n",
    "    convpool = DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
    "            num_units=512, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    # And, finally, the output layer with 50% dropout on its inputs:\n",
    "    convpool = lasagne.layers.DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
    "            num_units=nb_classes, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return convpool\n",
    "\n",
    "\n",
    "def build_convpool_conv1d(input_vars, nb_classes, imsize=32, n_colors=3, n_timewin=3):\n",
    "    \"\"\"\n",
    "    Builds the complete network with 1D-conv layer to integrate time from sequences of EEG images.\n",
    "\n",
    "    :param input_vars: list of EEG images (one image per time window)\n",
    "    :param nb_classes: number of classes\n",
    "    :param imsize: size of the input image (assumes a square input)\n",
    "    :param n_colors: number of color channels in the image\n",
    "    :param n_timewin: number of time windows in the snippet\n",
    "    :return: a pointer to the output of last layer\n",
    "    \"\"\"\n",
    "    convnets = []\n",
    "    w_init = None\n",
    "    # Build 7 parallel CNNs with shared weights\n",
    "    for i in range(n_timewin):\n",
    "        if i == 0:\n",
    "            convnet, w_init = build_cnn(input_vars[i], imsize=imsize, n_colors=n_colors)\n",
    "        else:\n",
    "            convnet, _ = build_cnn(input_vars[i], w_init=w_init, imsize=imsize, n_colors=n_colors)\n",
    "        convnets.append(FlattenLayer(convnet))\n",
    "    # at this point convnets shape is [numTimeWin][n_samples, features]\n",
    "    # we want the shape to be [n_samples, features, numTimeWin]\n",
    "    convpool = ConcatLayer(convnets)\n",
    "    convpool = ReshapeLayer(convpool, ([0], n_timewin, get_output_shape(convnets[0])[1]))\n",
    "    convpool = DimshuffleLayer(convpool, (0, 2, 1))\n",
    "    # input to 1D convlayer should be in (batch_size, num_input_channels, input_length)\n",
    "    convpool = Conv1DLayer(convpool, 64, 3)\n",
    "    # A fully-connected layer of 512 units with 50% dropout on its inputs:\n",
    "    convpool = DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
    "            num_units=512, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    # And, finally, the output layer with 50% dropout on its inputs:\n",
    "    convpool = DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
    "            num_units=nb_classes, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return convpool"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
